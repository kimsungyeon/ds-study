{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler((0,1))\n",
    "scaler.fit(X_train)\n",
    "X_train_transfoemd = scaler.transform(X_train)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_transformed)\n",
    "\n",
    "X_test_tr = scaler.transform(X_test)\n",
    "lr.predict(X_test_tr, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `sklearn.pipeline.Pipeline` 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pipe = Pipeline([\n",
    "    ('Normalization', MinMaxScaler(feature_range=(0, 1))), \n",
    "    ('LR', LogisticRegression(random_state=1234))\n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('Normalization', MinMaxScaler(copy=True, feature_range=(0, 1))), ('LR', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=1234, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print(norm_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_pipe = Pipeline([\n",
    "    ('Standardization', StandardScaler()),\n",
    "    ('LR', LogisticRegression(random_state=1234))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('Standardization', StandardScaler(copy=True, with_mean=True, with_std=True)), ('LR', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=1234, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print(stand_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'Normalization__feature_range': [(0, 1), (-0.5, 0.5), (-1, 1)],\n",
    "    'LR__C': [0.1, 0.5, 1.0, 5.0],\n",
    "    'LR__penalty': ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('Normalization', MinMaxScaler(copy=True, feature_range=(0, 1))), ('LR', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1234, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'Normalization__feature_range': [(0, 1), (-0.5, 0.5), (-1, 1)], 'LR__C': [0.1, 0.5, 1.0, 5.0], 'LR__penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_grid = GridSearchCV(norm_pipe, param_grid, cv=5, verbose=1)\n",
    "norm_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kth/miniconda3/envs/ml/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.66000, std: 0.01333, params: {'LR__C': 0.1, 'LR__penalty': 'l1', 'Normalization__feature_range': (0, 1)},\n",
       " mean: 0.72000, std: 0.04000, params: {'LR__C': 0.1, 'LR__penalty': 'l1', 'Normalization__feature_range': (-0.5, 0.5)},\n",
       " mean: 0.73333, std: 0.04216, params: {'LR__C': 0.1, 'LR__penalty': 'l1', 'Normalization__feature_range': (-1, 1)},\n",
       " mean: 0.69333, std: 0.02494, params: {'LR__C': 0.1, 'LR__penalty': 'l2', 'Normalization__feature_range': (0, 1)},\n",
       " mean: 0.80667, std: 0.06110, params: {'LR__C': 0.1, 'LR__penalty': 'l2', 'Normalization__feature_range': (-0.5, 0.5)},\n",
       " mean: 0.84000, std: 0.07424, params: {'LR__C': 0.1, 'LR__penalty': 'l2', 'Normalization__feature_range': (-1, 1)},\n",
       " mean: 0.87333, std: 0.04899, params: {'LR__C': 0.5, 'LR__penalty': 'l1', 'Normalization__feature_range': (0, 1)},\n",
       " mean: 0.89333, std: 0.06464, params: {'LR__C': 0.5, 'LR__penalty': 'l1', 'Normalization__feature_range': (-0.5, 0.5)},\n",
       " mean: 0.92000, std: 0.06182, params: {'LR__C': 0.5, 'LR__penalty': 'l1', 'Normalization__feature_range': (-1, 1)},\n",
       " mean: 0.80000, std: 0.07303, params: {'LR__C': 0.5, 'LR__penalty': 'l2', 'Normalization__feature_range': (0, 1)},\n",
       " mean: 0.85333, std: 0.07180, params: {'LR__C': 0.5, 'LR__penalty': 'l2', 'Normalization__feature_range': (-0.5, 0.5)},\n",
       " mean: 0.89333, std: 0.06799, params: {'LR__C': 0.5, 'LR__penalty': 'l2', 'Normalization__feature_range': (-1, 1)},\n",
       " mean: 0.90000, std: 0.06325, params: {'LR__C': 1.0, 'LR__penalty': 'l1', 'Normalization__feature_range': (0, 1)},\n",
       " mean: 0.92000, std: 0.06182, params: {'LR__C': 1.0, 'LR__penalty': 'l1', 'Normalization__feature_range': (-0.5, 0.5)},\n",
       " mean: 0.92667, std: 0.05735, params: {'LR__C': 1.0, 'LR__penalty': 'l1', 'Normalization__feature_range': (-1, 1)},\n",
       " mean: 0.84000, std: 0.07424, params: {'LR__C': 1.0, 'LR__penalty': 'l2', 'Normalization__feature_range': (0, 1)},\n",
       " mean: 0.87333, std: 0.07118, params: {'LR__C': 1.0, 'LR__penalty': 'l2', 'Normalization__feature_range': (-0.5, 0.5)},\n",
       " mean: 0.92000, std: 0.06182, params: {'LR__C': 1.0, 'LR__penalty': 'l2', 'Normalization__feature_range': (-1, 1)},\n",
       " mean: 0.94667, std: 0.03399, params: {'LR__C': 5.0, 'LR__penalty': 'l1', 'Normalization__feature_range': (0, 1)},\n",
       " mean: 0.94667, std: 0.03399, params: {'LR__C': 5.0, 'LR__penalty': 'l1', 'Normalization__feature_range': (-0.5, 0.5)},\n",
       " mean: 0.95333, std: 0.02667, params: {'LR__C': 5.0, 'LR__penalty': 'l1', 'Normalization__feature_range': (-1, 1)},\n",
       " mean: 0.90667, std: 0.07717, params: {'LR__C': 5.0, 'LR__penalty': 'l2', 'Normalization__feature_range': (0, 1)},\n",
       " mean: 0.92000, std: 0.06182, params: {'LR__C': 5.0, 'LR__penalty': 'l2', 'Normalization__feature_range': (-0.5, 0.5)},\n",
       " mean: 0.92667, std: 0.05735, params: {'LR__C': 5.0, 'LR__penalty': 'l2', 'Normalization__feature_range': (-1, 1)}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LR__C': 5.0, 'LR__penalty': 'l1', 'Normalization__feature_range': (-1, 1)}\n",
      "0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "print(norm_grid.best_params_)\n",
    "print(norm_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'LR__C': [0.1, 0.5, 1.0, 5.0],\n",
    "    'LR__penalty': ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('Standardization', StandardScaler(copy=True, with_mean=True, with_std=True)), ('LR', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1234, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'LR__C': [0.1, 0.5, 1.0, 5.0], 'LR__penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stand_grid = GridSearchCV(stand_pipe, param_grid, cv=5, verbose=1)\n",
    "stand_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kth/miniconda3/envs/ml/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.86667, std: 0.05578, params: {'LR__C': 0.1, 'LR__penalty': 'l1'},\n",
       " mean: 0.83333, std: 0.06992, params: {'LR__C': 0.1, 'LR__penalty': 'l2'},\n",
       " mean: 0.91333, std: 0.06864, params: {'LR__C': 0.5, 'LR__penalty': 'l1'},\n",
       " mean: 0.88000, std: 0.06864, params: {'LR__C': 0.5, 'LR__penalty': 'l2'},\n",
       " mean: 0.93333, std: 0.04714, params: {'LR__C': 1.0, 'LR__penalty': 'l1'},\n",
       " mean: 0.90667, std: 0.06464, params: {'LR__C': 1.0, 'LR__penalty': 'l2'},\n",
       " mean: 0.95333, std: 0.03399, params: {'LR__C': 5.0, 'LR__penalty': 'l1'},\n",
       " mean: 0.93333, std: 0.04714, params: {'LR__C': 5.0, 'LR__penalty': 'l2'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stand_grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LR__C': 5.0, 'LR__penalty': 'l1'}\n",
      "0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "print(stand_grid.best_params_)\n",
    "print(stand_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `sklearn.pipeline.make_pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pipe = make_pipeline(\n",
    "    MinMaxScaler(feature_range=(0,1)), \n",
    "    LogisticRegression(random_state=1234)\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=1234, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print(norm_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    LogisticRegression(random_state=1234)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform. '('aa', StandardScaler(copy=True, with_mean=True, with_std=True))' (type <class 'tuple'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b1e9b34bacd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m stand_pipe = make_pipeline(\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'aa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'bb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mmake_pipeline\u001b[0;34m(*steps, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m         raise TypeError('Unknown keyword arguments: \"{}\"'\n\u001b[1;32m    562\u001b[0m                         .format(list(kwargs.keys())[0]))\n\u001b[0;32m--> 563\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_name_estimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 raise TypeError(\"All intermediate steps should be \"\n\u001b[1;32m    161\u001b[0m                                 \u001b[0;34m\"transformers and implement fit and transform.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                                 \" '%s' (type %s) doesn't\" % (t, type(t)))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# We allow last estimator to be None as an identity transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform. '('aa', StandardScaler(copy=True, with_mean=True, with_std=True))' (type <class 'tuple'>) doesn't"
     ]
    }
   ],
   "source": [
    "# 모듈에 이름을 붙이면 error 발생\n",
    "stand_pipe = make_pipeline(\n",
    "    ('aa', StandardScaler()), \n",
    "    ('bb', LogisticRegression(random_state=1234))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=1234, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print(stand_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'logisticregression__C': [0.1, 0.5, 1.0, 5.0],\n",
    "    'logisticregression__penalty': ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1234, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'logisticregression__C': [0.1, 0.5, 1.0, 5.0], 'logisticregression__penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_grid = GridSearchCV(norm_pipe, param_grid, cv=5, verbose=1)\n",
    "norm_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1234, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'logisticregression__C': [0.1, 0.5, 1.0, 5.0], 'logisticregression__penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stand_grid = GridSearchCV(stand_pipe, param_grid, cv=4, verbose=1)\n",
    "stand_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
